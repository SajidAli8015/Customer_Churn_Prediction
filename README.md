# ğŸ“ Churn Prediction for Telecom Customers

This project focuses on predicting customer churn for a telecom company using machine learning techniques. The goal is to build an end-to-end churn prediction system that can identify customers likely to churn and help businesses take proactive retention actions.

---

## ğŸ¯ Project Objectives

- Build a robust churn prediction model using real customer data
- Improve recall to correctly identify as many churners as possible
- Perform advanced feature engineering and model explainability (SHAP)
- Compare multiple models: Logistic Regression, Random Forest, and LightGBM
- Select the best model and deploy it as an API with a user interface (Flask)
- Package the app using Docker for portable deployment

---

## ğŸ“Š Key Highlights

- ğŸ“‚ Realistic customer data with over 30+ features
- ğŸ§  Advanced Feature Engineering & Encoding
- âš–ï¸ Addressed class imbalance using SMOTE and `scale_pos_weight`
- âœ… Model Evaluation with Precision, Recall, AUC, and F1 Score
- ğŸ¯ Threshold optimization to improve recall without hurting precision
- ğŸŒ Model Deployment using Flask API + Streamlit UI + Docker container

---

## ğŸ” Dataset Overview

The dataset contains customer-level information such as:

- **Demographics** (Gender, Senior Citizen, Partner, etc.)
- **Services** (Internet, Streaming, Device Protection, etc.)
- **Account Info** (Tenure, MonthlyCharges, Contract Type)
- **Target Variable**: `Churn` (Yes/No)

---

## ğŸ“‚ Project Structure

```
Churn_Prediction/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                     # Original CSV file
â”‚   â”œâ”€â”€ processed/               # Cleaned and encoded data
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_preprocessing.ipynb        # Load and clean raw data
â”‚   â”œâ”€â”€ 02_feature_preparation.ipynb       # Feature engineering + encoding
â”‚   â”œâ”€â”€ 03_logistic_regression_modeling.ipynb
â”‚   â”œâ”€â”€ 04_random_forest_modeling.ipynb
â”‚   â”œâ”€â”€ 05_lightgbm_modeling.ipynb
â”‚
â”œâ”€â”€ deployment/
â”‚   â”œâ”€â”€ final_logreg_model.pkl
â”‚   â”œâ”€â”€ final_rf_model.pkl
â”‚   â”œâ”€â”€ final_lightgbm_model.pkl
â”‚   â”œâ”€â”€ shap_selected_features.pkl
â”‚   â”œâ”€â”€ app.py                  # Flask app (API)
â”‚   â”œâ”€â”€ ui_streamlit.py         # Streamlit frontend (UI)
â”‚   â”œâ”€â”€ Dockerfile              # Docker setup
â”‚
â”œâ”€â”€ src/                        # (To add any helper scripts later)
â”‚
â”œâ”€â”€ requirements.txt          # Minimal dependencies for running app
â”œâ”€â”€ requirements-dev.txt      # Full dev setup (SHAP, Jupyter, etc.)
â”œâ”€â”€ README.md
```

---

## ğŸ”§ Feature Engineering

Several new features were created:

- `is_long_term_contract`
- `has_bundle`
- `is_senior_alone`
- `low_tenure_high_charge`
- `is_tech_dependent`
- `total_services`: based on cleaned service columns

Also, `TotalCharges` was converted from object to numeric and cleaned.

---

## ğŸ§ª Feature Selection

- For **Logistic Regression**: Recursive Feature Elimination with Cross Validation (RFECV)
- For **Random Forest** & **LightGBM**: SHAP values used to select top features
- Highly correlated features were removed based on SHAP importance

---

## âš™ï¸ Model Building Workflow

1. **Baseline Model**: Logistic Regression
2. **Model 2**: Random Forest (SHAP + grid search)
3. **Model 3**: LightGBM (SHAP + grid search)

All models evaluated using F1, Recall, Precision, AUC.

---

## ğŸ“ˆ Model Evaluation Summary

| Model                | Precision | Recall | F1 Score | AUC     |
|---------------------|-----------|--------|----------|---------|
| Logistic Regression | 0.61      | 0.65   | 0.63     | 0.83    |
| Random Forest        | 0.49      | 0.83   | 0.62     | 0.83    |
| **LightGBM**      | **0.59**  | **0.81** | **0.69** | **0.83** |

> **Final Model Selected: LightGBM** - Best balance between recall and precision

---

## ğŸ› ï¸ Tools & Libraries

- Python 3.8+
- Pandas, NumPy
- Scikit-Learn
- LightGBM
- SHAP
- imbalanced-learn
- Matplotlib / Seaborn
- Flask (for deployment)
- Docker (for containerization)

---

## ğŸš€ Deployment Plan

The final LightGBM model will be deployed using:

- âœ… **Flask API** to serve model predictions
- âœ… **Frontend UI** (HTML or Streamlit) to input customer features and receive predictions
- âœ… **Docker** for containerized deployment (portable & consistent)
- â˜ï¸ Hosting options: Render / Heroku / Railway / Localhost

Model files:
- `final_lightgbm_model.pkl`
- `final_rf_model.pkl`
- `final_logreg_model.pkl`

**Requirements Files:**
- `requirements.txt`: Minimal set required to run the app
- `requirements-dev.txt`: Full environment with SHAP, Jupyter, etc. (for local development or debugging)

---

## ğŸš§ Future Improvements

- â³ Automate model retraining pipeline (with updated customer data)
- ğŸ’¬ Add real-time feedback loop for improved accuracy
- ğŸŒ Host the Flask API + UI using a cloud platform
- ğŸ§ª Add unit tests and model drift detection
- ğŸ“Š Integrate model into CRM dashboard for business use
- ğŸ” Explore deep learning models like TabNet or CatBoost
- ğŸ§© Add interpretability dashboard using SHAP for business users

---

## ğŸ‘¤ Author

**Sajid Ali**  
Data Scientist | Machine Learning | AI for Telecom  
ğŸ“§ alisajid8030@gmail.com 

---

## ğŸ“ License

This project is open for learning, demonstration, and portfolio use only.
